{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZJ6l2eq6NKaK/mKE2Sh+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pardhavkrishna21/huggingface-colab-experiments/blob/main/ner_classification_tts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILNEsDugxO6j"
      },
      "outputs": [],
      "source": [
        "pip install -q transformers datasets diffusers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import the required things\n"
      ],
      "metadata": {
        "id": "JWpLWCuPx-CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from diffusers import DiffusionPipeline\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "qpsDUAzbx5GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "trying different things\n"
      ],
      "metadata": {
        "id": "AMbWd4jWyW21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment Analysis\n",
        "classifier = pipeline(\"sentiment-analysis\",device=-1)\n",
        "result = classifier(\"I'm super excited to be on the way to LLM mastery!\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "HOXbsQZvyfYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Named Entity Recognition\n",
        "ner = pipeline(\"ner\", grouped_entities=True, device=-1)\n",
        "result = ner(\"Barack Obama was the 44th president of the United States.\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Ws7vWrd7zjsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question Answering with Context\n",
        "question_answerer = pipeline(\"question-answering\", device=-1)\n",
        "result = question_answerer(question=\"Who was the 44th president of the United States?\", context=\"Barack Obama was the 44th president of the United States.\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "bzjzgsde1Ehp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Summarization\n",
        "summarizer = pipeline(\"summarization\", device=-1)\n",
        "text = \"\"\"GPT-5 is OpenAIâ€™s latest large language model designed to push the boundaries of reasoning, creativity, and problem-solving.\n",
        "Compared to its predecessors, it demonstrates stronger contextual understanding, more accurate information retrieval, and improved efficiency across diverse tasks like coding, research, education, and content creation.\n",
        "GPT-5 is also better aligned with user intent, reducing errors and producing more reliable outputs.\n",
        "It supports multimodal inputs, handling text and images seamlessly, and is built with enhanced safety layers to ensure responsible use.\n",
        " With these advancements, GPT-5 serves as a powerful assistant for students, professionals, and innovators across industries worldwide.\n",
        " \"\"\"\n",
        "summary = summarizer(text, max_length=50,min_length=25, do_sample=False)\n",
        "print(summary[0]['summary_text'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DYDkdT7G2J2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Translation\n",
        "translator = pipeline(\"translation_en_to_fr\", device=-1)\n",
        "result = translator(\"The Data Scientists were truly amazed by the power and simplicity of the HuggingFace pipeline API.\")\n",
        "print(result[0] ['translation_text'])"
      ],
      "metadata": {
        "id": "-4hNgIoP4XuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification\n",
        "classifier= pipeline(\"zero-shot-classification\", device=-1)\n",
        "result = classifier(\"Hugging Face's Transformers library is amazing!\", candidate_labels=[\"technology\", \"sports\", \"politics\"])\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "Mg_MBSF95CIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Generation\n",
        "generator =pipeline(\"text-generation\", device=-1)\n",
        "result = generator(\"If there's one thing I want you to remember about using Hugging Face pipelines, it's\")\n",
        "print(result[0] ['generated_text'])\n"
      ],
      "metadata": {
        "id": "hPV0vR2w5s8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Audio Generation\n",
        "synthesiser = pipeline(\"text-to-speech\", \"microsoft/speecht5_tts\", device=-1)\n",
        "# Create a random default speaker embedding (shape: [1, 512])\n",
        "speaker_embedding = torch.randn(1, 512)\n",
        "\n",
        "speech = synthesiser(\n",
        "    \"Hi to an artificial intelligence engineer, on the way to mastery!\",\n",
        "    forward_params={\"speaker_embeddings\": speaker_embedding}\n",
        ")\n",
        "\n",
        "sf.write(\"speech.wav\", speech[\"audio\"], samplerate=speech[\"sampling_rate\"])\n",
        "Audio(\"speech.wav\")\n"
      ],
      "metadata": {
        "id": "U1t6hs3f-usb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}